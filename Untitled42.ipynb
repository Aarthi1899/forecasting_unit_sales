{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "fcHoeqKw0YwO"
      },
      "outputs": [],
      "source": [
        "# NSS AARTHI\n",
        "# !pip install fbprophet\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "# from fbprophet import Prophet # Now this import should work\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense\n",
        "\n",
        "# Load data\n",
        "train_data = pd.read_csv('/content/train.csv')\n",
        "test_data = pd.read_csv('/content/test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "cujJhAlitGLF"
      },
      "outputs": [],
      "source": [
        "# Convert dates\n",
        "train_data['date'] = pd.to_datetime(train_data['date'])\n",
        "test_data['date'] = pd.to_datetime(test_data['date'])\n",
        "\n",
        "# Fill missing values\n",
        "train_data.fillna({'ad_spend': train_data['ad_spend'].median()}, inplace=True)\n",
        "test_data.fillna({'ad_spend': test_data['ad_spend'].median()}, inplace=True)\n",
        "\n",
        "#Feature engineering\n",
        "train_data['day_of_week'] = train_data['date'].dt.dayofweek\n",
        "train_data['month'] = train_data['date'].dt.month\n",
        "train_data['lag_1'] = train_data['units'].shift(1)\n",
        "train_data.dropna(inplace=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BF7Dap8NtH2M",
        "outputId": "d2538495-26c7-4f7c-bd11-befc3074070f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Forest MSE: 3239.5734415056418\n"
          ]
        }
      ],
      "source": [
        "X = train_data[['ad_spend', 'day_of_week', 'month', 'lag_1']]\n",
        "y = train_data['units']\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "rf_predictions = rf_model.predict(X_val)\n",
        "rf_mse = mean_squared_error(y_val, rf_predictions)\n",
        "print(f'Random Forest MSE: {rf_mse}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "SGA97G_c89Zi"
      },
      "outputs": [],
      "source": [
        "test_data['date'] = pd.to_datetime(test_data['date'])\n",
        "test_data.sort_values('date', inplace=True)\n",
        "\n",
        "# Extract day of the week and month from the 'date' column if necessary\n",
        "test_data['day_of_week'] = test_data['date'].dt.dayofweek\n",
        "test_data['month'] = test_data['date'].dt.month\n",
        "\n",
        "\n",
        "test_data['lag_1'] = test_data['ad_spend'].shift(1).fillna(0)  # Using ad_spend for lag creation\n",
        "\n",
        "# Select the same features used in the model training\n",
        "test_features = test_data[['ad_spend', 'day_of_week', 'month', 'lag_1']]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "QdMJmt9Q9ArO"
      },
      "outputs": [],
      "source": [
        "# Make predictions\n",
        "predictions = rf_model.predict(test_features)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "MByYRlq79Cvm"
      },
      "outputs": [],
      "source": [
        "# Assuming the test_data has an 'ID' column as in your provided sample\n",
        "test_data['TARGET'] = predictions\n",
        "\n",
        "# Create a DataFrame for submission\n",
        "submission = test_data[['ID', 'TARGET']]\n",
        "\n",
        "# Save the submission to a CSV file\n",
        "submission.to_csv('/content/submissions.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfhv-2z9tMdE",
        "outputId": "f2d4b811-36a1-4f0f-a821-924f3af73c24"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "59628/59628 - 117s - 2ms/step - loss: 4094.8955\n",
            "Epoch 2/20\n",
            "59628/59628 - 114s - 2ms/step - loss: 4072.0369\n",
            "Epoch 3/20\n",
            "59628/59628 - 139s - 2ms/step - loss: 4052.3289\n",
            "Epoch 4/20\n",
            "59628/59628 - 146s - 2ms/step - loss: 4031.1575\n",
            "Epoch 5/20\n",
            "59628/59628 - 117s - 2ms/step - loss: 3992.2595\n",
            "Epoch 6/20\n",
            "59628/59628 - 114s - 2ms/step - loss: 3971.3132\n",
            "Epoch 7/20\n",
            "59628/59628 - 142s - 2ms/step - loss: 3970.1990\n",
            "Epoch 8/20\n",
            "59628/59628 - 114s - 2ms/step - loss: 3987.0161\n",
            "Epoch 9/20\n",
            "59628/59628 - 149s - 2ms/step - loss: 3984.0959\n",
            "Epoch 10/20\n",
            "59628/59628 - 113s - 2ms/step - loss: 3948.0845\n",
            "Epoch 11/20\n",
            "59628/59628 - 146s - 2ms/step - loss: 3939.2422\n",
            "Epoch 12/20\n",
            "59628/59628 - 114s - 2ms/step - loss: 3925.4709\n",
            "Epoch 13/20\n",
            "59628/59628 - 144s - 2ms/step - loss: 3955.0356\n",
            "Epoch 14/20\n",
            "59628/59628 - 140s - 2ms/step - loss: 3957.1453\n",
            "Epoch 15/20\n",
            "59628/59628 - 113s - 2ms/step - loss: 3920.3359\n",
            "Epoch 16/20\n",
            "59628/59628 - 151s - 3ms/step - loss: 3920.9014\n",
            "Epoch 17/20\n",
            "59628/59628 - 141s - 2ms/step - loss: 3916.9612\n",
            "Epoch 18/20\n",
            "59628/59628 - 140s - 2ms/step - loss: 3910.9636\n",
            "Epoch 19/20\n",
            "59628/59628 - 114s - 2ms/step - loss: 3906.6025\n",
            "Epoch 20/20\n",
            "59628/59628 - 116s - 2ms/step - loss: 3856.2197\n",
            "\u001b[1m466/466\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "LSTM MSE: 9207.498345380334\n"
          ]
        }
      ],
      "source": [
        "X_train_lstm = np.reshape(X_train.values, (X_train.shape[0], 1, X_train.shape[1]))\n",
        "X_val_lstm = np.reshape(X_val.values, (X_val.shape[0], 1, X_val.shape[1]))\n",
        "\n",
        "lstm_model = Sequential([\n",
        "    LSTM(50, input_shape=(1, X_train.shape[1])),\n",
        "    Dense(1)\n",
        "])\n",
        "lstm_model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "lstm_model.fit(X_train_lstm, y_train, epochs=20, batch_size=1, verbose=2)\n",
        "\n",
        "lstm_predictions = lstm_model.predict(X_val_lstm)\n",
        "lstm_mse = mean_squared_error(y_val, [x[0] for x in lstm_predictions])\n",
        "print(f'LSTM MSE: {lstm_mse}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "OELPGB2V_gzj"
      },
      "outputs": [],
      "source": [
        "\n",
        "test_features_lstm = np.reshape(test_features.values, (test_features.shape[0], 1, test_features.shape[1]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gh8stwmr_jCI",
        "outputId": "32b3682f-8c02-4150-efc7-60ae9c5b6fba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
          ]
        }
      ],
      "source": [
        "# predictions using the trained LSTM model\n",
        "test_predictions_lstm = lstm_model.predict(test_features_lstm)\n",
        "#Flatten the predictions to fit the submission format\n",
        "test_predictions_lstm = test_predictions_lstm.flatten()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5bn4iCm__lov"
      },
      "outputs": [],
      "source": [
        "# Assuming the test_data has an 'ID' column as in your provided sample\n",
        "test_data['TARGET'] = test_predictions_lstm\n",
        "\n",
        "# Create a DataFrame for submission\n",
        "submission_lstm = test_data[['ID', 'TARGET']]\n",
        "\n",
        "# Save the submission to a CSV file\n",
        "submission_lstm.to_csv('/content/lstm_submissions.csv', index=False)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
